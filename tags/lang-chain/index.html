<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">One post tagged with &quot;LangChain&quot; | Sumi Elizabeth Joseph</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://ejsumi.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://ejsumi.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://ejsumi.github.io/tags/lang-chain"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="One post tagged with &quot;LangChain&quot; | Sumi Elizabeth Joseph"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="canonical" href="https://ejsumi.github.io/tags/lang-chain"><link data-rh="true" rel="alternate" href="https://ejsumi.github.io/tags/lang-chain" hreflang="en"><link data-rh="true" rel="alternate" href="https://ejsumi.github.io/tags/lang-chain" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/rss.xml" title="Sumi Elizabeth Joseph RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Sumi Elizabeth Joseph Atom Feed">




<link rel="icon" type="image/svg+xml" href="/img/favicon.svg"><link rel="stylesheet" href="/assets/css/styles.f3e07ab7.css">
<script src="/assets/js/runtime~main.56212fbf.js" defer="defer"></script>
<script src="/assets/js/main.ab125dc3.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Sumi Elizabeth Joseph" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Sumi Elizabeth Joseph" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Sumi </b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">Blog</a><a class="navbar__item navbar__link" href="/about">About</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://www.linkedin.com/in/sumi-elizabeth-joseph/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">LinkedIn<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All Posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2026</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/2026/02/14/rag-poc">RAG from the Inside: What Building It Taught Me About AI-Readable Docs</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/2026/01/25/jekyll-to-docusaurus">From Jekyll to Docusaurus</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/2026/01/10/aiagents">Understanding AI Agents</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/2025/11/13/ml-classification-vs-regression">Machine Learning Practice Problems: Classification vs Regression</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/2025/10/28/supervised-learning">Supervised Learning: A Quick Reference</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/2025/10/02/copilitusage">My Daily Workflow with Enterprise Copilot: A Technical Writer&#x27;s Field Notes</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/2025/09/13/pandas-groupby">Pandas GroupBy in Practice: Real-World Scenarios and What to Watch Out For</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/2025/08/15/numpy">Numpy: A Quick Reference</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/2025/08/08/msty">Maximizing AI Value: Comparing Models and Saving Money with Msty</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/2025/08/01/pandas">Pandas: A Quick Reference</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/2025/07/28/project1">Enterprise Content Evolution: Migrating Platforms</a></li></ul></div></nav></aside><main class="col col--7"><header class="margin-bottom--xl"><h1>One post tagged with &quot;LangChain&quot;</h1><a href="/tags">View All Tags</a></header><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/2026/02/14/rag-poc">RAG from the Inside: What Building It Taught Me About AI-Readable Docs</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2026-02-14T00:00:00.000Z">February 14, 2026</time> · <!-- -->6 min read</div></header><div class="markdown"><p>The ask for technical writers team is to make product documentation both human-readable and AI-readable. The idea is that if a RAG-based system is already being used in the knowledge portal to answer user questions, the quality of those answers depends entirely on how well-structured the source documents are. To understand on to make documents AI scalable, I need to actually understand how RAG works from the inside — not just conceptually, but what happens when you feed it a document and ask a question.</p>
<p>So I built a POC. I learned a lot more than I expected.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-rag-actually-is">What RAG Actually Is<a href="#what-rag-actually-is" class="hash-link" aria-label="Direct link to What RAG Actually Is" title="Direct link to What RAG Actually Is" translate="no">​</a></h2>
<p>The short version: RAG lets you ask questions about documents that you upload.</p>
<p>Here&#x27;s the thing about regular ChatGPT or any LLM — it only knows what it was trained on. Ask it about your internal policy document or a PDF from last week, and it either makes something up or tells you it doesn&#x27;t know.</p>
<p>RAG fixes this. Not by retraining the model, but by retrieving the relevant parts of your document and feeding them to the model alongside your question. The model then generates an answer based on what you just handed it, not from memory.</p>
<p>There are two distinct phases:</p>
<p><strong>Indexing</strong> — happens once when you add documents:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">PDF → Extract Text → Chunk → Embed → Store in VectorDB</span><br></span></code></pre></div></div>
<p><strong>Querying</strong> — happens every time someone asks a question:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Question → Embed → Search VectorDB → Retrieve Chunks → LLM → Answer</span><br></span></code></pre></div></div>
<p>The key insight that changed how I think about it: the LLM never &quot;reads&quot; your PDF. It only sees the handful of chunks that were retrieved as most relevant to the question. If the retrieval is off, the answer will be off — no matter how capable the model is.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-langchain-and-chromadb">Why LangChain and ChromaDB<a href="#why-langchain-and-chromadb" class="hash-link" aria-label="Direct link to Why LangChain and ChromaDB" title="Direct link to Why LangChain and ChromaDB" translate="no">​</a></h2>
<p>I had a few options for how to build this. I went with LangChain as the orchestration layer and ChromaDB as the vector store, and the reason was simple: I wanted to get something working first and understand the concepts. Also, was doing a course on Langchain and RAG, so easier to go with what I was learning.</p>
<p><strong>What LangChain is:</strong> It&#x27;s an open-source framework for building LLM-powered applications. Instead of writing all the plumbing yourself — API calls, prompt construction, memory management, retrieval logic — LangChain gives you composable building blocks. For this POC, the components I used were:</p>
<ul>
<li class=""><strong>ChatOpenAI</strong> — wrapper around OpenAI&#x27;s chat model, handles API calls and response parsing</li>
<li class=""><strong>ConversationalRetrievalChain</strong> — the core chain that ties everything together: takes a question, retrieves relevant chunks, builds the prompt, calls the LLM, and returns the answer</li>
<li class=""><strong>ConversationBufferMemory</strong> — stores the chat history so follow-up questions work without re-asking context</li>
<li class=""><strong>PromptTemplate</strong> — structures exactly what gets sent to the LLM, including how context and question are combined</li>
<li class=""><strong>Retriever</strong> — the interface that queries ChromaDB and returns the top K matching chunks</li>
</ul>
<p>ChromaDB runs locally, requires no server setup, and stores vectors on disk. Together, they let you go from zero to a working Q&amp;A system in a few hours.</p>
<p>The tradeoff is real though. LangChain is a thick abstraction layer. You call high-level functions without fully seeing what&#x27;s happening underneath — how the HTTP calls to the embedding API work, exactly how the similarity search runs, how context is being assembled before it hits the LLM. It works, but it hides the internals.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-i-actually-built">What I Actually Built<a href="#what-i-actually-built" class="hash-link" aria-label="Direct link to What I Actually Built" title="Direct link to What I Actually Built" translate="no">​</a></h2>
<p>The POC is a Streamlit app that:</p>
<ul>
<li class="">Accepts a PDF upload</li>
<li class="">Chunks and embeds the text using OpenAI&#x27;s embedding model</li>
<li class="">Stores the vectors in ChromaDB</li>
<li class="">Accepts questions in a chat interface</li>
<li class="">Retrieves the top K relevant chunks and sends them to the LLM</li>
<li class="">Returns an answer with source citations showing which parts of the document it drew from</li>
</ul>
<p>Three components, each independently tuneable:</p>
<table><thead><tr><th>Component</th><th>What It Does</th><th>What I Used</th></tr></thead><tbody><tr><td>PDF Processor</td><td>Extracts and chunks the text</td><td>pypdf + LangChain text splitter</td></tr><tr><td>Embedding Model</td><td>Converts chunks to vectors for search</td><td>text-embedding-3-small</td></tr><tr><td>LLM</td><td>Generates answers from retrieved chunks</td><td>gpt-4o-mini</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="tuning-it--what-actually-changes-responses">Tuning It — What Actually Changes Responses<a href="#tuning-it--what-actually-changes-responses" class="hash-link" aria-label="Direct link to Tuning It — What Actually Changes Responses" title="Direct link to Tuning It — What Actually Changes Responses" translate="no">​</a></h2>
<p>This is where it got interesting.</p>
<p>The first answers I got were technically correct but flat. Too literal. The model was pulling exact phrases from the document and reciting them without much synthesis. I started tuning.</p>
<p><strong>The prompt template</strong> made the biggest difference. Changing how I framed the task — what tone to use, how to handle uncertainty, whether to synthesize across chunks or quote directly — changed the response quality significantly. This is free to change and has no latency cost.</p>
<p><strong>Temperature</strong> was the one that surprised me most. At low temperature (around 0.1–0.2), the model becomes very conservative. It sticks close to exact wording in the retrieved chunks. If the question uses slightly different phrasing than the document, it can fail to connect them — even when a human would obviously see the relationship. It&#x27;s not that the answer is wrong; it&#x27;s that it&#x27;s too literal.</p>
<p>Raising the temperature to around 0.5–0.7 made the responses more natural and better at bridging paraphrase gaps. The model was more willing to interpret rather than just recite. For factual Q&amp;A, somewhere in the 0.3–0.5 range felt like the right balance — enough flexibility to handle varied phrasing, not so much that it starts drifting from what&#x27;s actually in the document.</p>
<p>The other parameters worth knowing:</p>
<ul>
<li class=""><strong>RETRIEVAL_K</strong> — how many chunks get passed to the LLM. More chunks = more context. Going from 3 to 6 noticeably improved answers on complex questions where context was spread across the document.</li>
<li class=""><strong>CHUNK_SIZE / CHUNK_OVERLAP</strong> — smaller chunks give more precise retrieval but can miss context that spans paragraphs. Larger chunks capture more context but can bring in irrelevant content. Changing these requires re-indexing everything.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-bottom-line">The Bottom Line<a href="#the-bottom-line" class="hash-link" aria-label="Direct link to The Bottom Line" title="Direct link to The Bottom Line" translate="no">​</a></h2>
<p>RAG is conceptually simple. Two phases, three components. The hard part is understanding which component to adjust when the answers aren&#x27;t good enough — and right now, the fastest levers are the prompt template, retrival chunks and temperature.</p>
<p>LangChain and ChromaDB are the right tools to start with. They get you to a working system quickly so you can focus on what actually matters: the quality of retrieval and the quality of the prompts.</p>
<p>Once you&#x27;ve got that, you peel back the abstraction and build it the hard way. That&#x27;s where the real understanding is. Next up: rebuilding this without LangChain — raw API calls, custom chunking, manual prompt construction — to see exactly what the framework was doing for me.</p>
<hr>
<p><em>Built with Python, LangChain, ChromaDB, and OpenAI. Running locally with Streamlit.</em></p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/tags/python">python</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/tags/gen-ai">Gen AI</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/tags/rag">RAG</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/tags/lang-chain">LangChain</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/tags/personal-project">personal project</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Explore</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/">Blog</a></li><li class="footer__item"><a class="footer__link-item" href="/about">About</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Connect</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/sumi-elizabeth-joseph/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 Sumi Elizabeth Joseph. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>