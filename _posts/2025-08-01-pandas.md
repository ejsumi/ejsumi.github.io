---
title: "Pandas: A Quick Reference"
categories: [learnings]
tags: [python, data analysis]
---

- Open source library for Data Analysis and Data manipulation
- Built on top of NumPy and integrates well with other libraries like Matplotlib, Seaborn, Scikit-learn

2 primary data structures
- Series - 1 D array
- DataFrames - 2 D array heterogeneous table like Excel, SQL, with rows and columns.

## Key Features
- **Easy Handling of Missing Data** - - With functions like .fillna(), .dropna(), and more.

- **Data Alignment and Indexing** allows for label-based and position-based data selection and slicing.
 
- **Data Filtering and Transformation** - using conditions, and transformation using apply(), map(), etc.

- **Merging and Joining** - Similar to SQL joins via merge(), join(), and concat() functions.

- **GroupBy Functionality** - Split data into groups, apply operations, and combine results.

- **Time Series Support** - Built-in support for date and time operations.

- **Read/Write from Multiple File Formats** - Supports CSV, Excel, JSON, SQL, and more.


## Quick Reference

### Load a CSV File

```python
df = pd.read_csv('data.csv')
```

### Dropping a Column

```python
df = df.drop('column_name', axis=1)
```

###  Filling Missing Values 

- with Median

```python
df['col'] = df['col'].fillna(df['col'].median())
```

- with Mode

```python
df['col'] = df['col'].fillna(df['col'].mode()[0])
```

### Combining Two Columns into One

```python
df['combined'] = df['col1'].astype(str) + '_' + df['col2'].astype(str)
```

### Converting to Numeric (with errors turned to NaN)

```python
df['col'] = pd.to_numeric(df['col'], errors='coerce')
```

### Filtering Rows Based on Condition

```python
filtered_df = df[df['col'] > 10]
```
### One-Hot Encoding Categorical Features

```python
df = pd.get_dummies(df, columns=['category_column'])
```

### Label Encoding

```python
df['encoded'] = df['category_column'].astype('category').cat.codes
```

### Rename Columns

```python
df = df.rename(columns={'old_name': 'new_name'})
```

### Groupby and Aggregate

```python
grouped = df.groupby('category')['col'].mean()
```

### Sorting DataFrame

```python
df = df.sort_values(by='col', ascending=False)
```

### Reset Index

```python
df = df.reset_index(drop=True)
```

### Selecting Multiple Columns

```python
selected = df[['col1', 'col2', 'col3']]
```

### Date time operations
-  Conversion to date time column
```python
df['date_column'] = pd.to_datetime(df['date_column'])
```

-  Extract Date, Year, Month, and Day
```python
df['date'] = df['date_column'].dt.date        # Extract date
df['year'] = df['date_column'].dt.year        # Extract year
df['month'] = df['date_column'].dt.month      # Extract month
df['day'] = df['date_column'].dt.day          # Extract day
```

- Extract Time Component
```python
df['time'] = df['date_column'].dt.time
```

- Combine Year, Month, Day, and Time Columns into a Single Datetime
```python
df['datetime'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute', 'second']])
```

- Filter or Select Data for a Specific Time Period
```python
df[(df['date_column'] >= '2023-01-01') & (df['date_column'] < '2024-01-01')]
```

Tip: Use .dt accessor for various datetime features (like dt.hour, dt.minute, dt.dayofweek, etc.) to further engineer time-related columns or extract more granularity from your datetime data

### Replace Operations

- Replace specific characters

*Replace spaces and '/' with NaN in all columns*
```python
df.replace([' ', '/'], np.nan, inplace=True)
```

*Replace only in a specific column*
```python
df['col'] = df['col'].replace([' ', '/'], np.nan)
```

- Replace using Regex

*Replace spaces and '/' characters with NaN using regex in a column*
```python
df['col'] = df['col'].replace(r'[ /]', np.nan, regex=True)
```
*To replace with another value (e.g., 'missing')*
```python
df['col'] = df['col'].replace(r'[ /]', 'missing', regex=True)
```

Tip:

- Use np.nan to replace with NaN.
- Use the regex=True argument to match patterns (e.g., all whitespace or special characters).
- Set inplace=True to modify the DataFrame directly.
- These patterns work for spaces, slashes, or any regex you specify!

